\chapter{线性映射矩阵表示}

在上一讲的讨论中我们定义了线性映射的基本概念与性质，以及线性映射像空间与核空间之间的关联，引出了我们目前为止最核心的概念——同构. 同构使得我们研究的抽象层次更上一层，而本讲将在这抽象的制高点获得最具象的表达形式——矩阵，介绍线性映射矩阵表示的定义，以及这一定义下线性映射与矩阵的一一对应关系，从而使得我们后续的研究都可以基于具象的矩阵.

\section{线性映射矩阵表示}

最开始我们在高斯消元时引入了矩阵作为符号简化和方程组求解的工具，严格地来说，我们之前的定义是：
\begin{definition}{}{}
    域$\mathbf{F}$中的$m\times n$个元素$a_{ij}\enspace(i=1,\ldots,m,\enspace j=1,\ldots,n)$排成$m$行$n$列的矩形数表，称为域$\mathbf{F}$上的一个$m\times n$矩阵，记作
    \[A=\begin{pmatrix}
            a_{11} & a_{12} & \cdots & a_{1n} \\
            a_{21} & a_{22} & \cdots & a_{2n} \\
            \vdots & \vdots & \ddots & \vdots \\
            a_{m1} & a_{m2} & \cdots & a_{mn}
        \end{pmatrix}\]
    或简记为$(a_{ij})_{m\times n}$，其中$a_{ij}$表示矩阵$A$的第$i$行第$j$列的元素.
\end{definition}

但是笔者将会在下文用不同的方式引出一种新的定义. 为了探究线性映射的性质，我们需要先研究一些特殊案例，然后从特殊到一般，矩阵就是对特殊案例——$\mathbf{F}^n$ 这样空间的研究. 不妨先考察 $\mathbf{F}^n\to\mathbf{F}^m$ 的线性映射，其可以写成 $y = \sigma(x)$，其中 $x\in\mathbf{F}^n, y\in\mathbf{F}^m$. 我们给出如下结论：
\begin{lemma}{}{}
    设
    \begin{align*}
        \sigma \colon \mathbf{F}^n &\to \mathbf{F}^m \\
        x = (x_1, \cdots, x_n) & \mapsto y = (y_1, \cdots, y_m)
    \end{align*}
    是线性映射，则映射具有形式，称矩阵 $(a_{ij})_{m\times n}$ 为线性映射 $\sigma\colon\mathbf{F}^n\to\mathbf{F}^m$ 的标准表示
    \begin{align*}
        y_1 &= a_{11} x_1 + a_{12} x_2 + \cdots + a_{1n} x_n \\
        y_2 &= a_{21} x_1 + a_{22} x_2 + \cdots + a_{2n} x_n \\
        & \cdots\\
        y_m &= a_{m1} x_1 + a_{m2} x_2 + \cdots + a_{mn} x_n
    \end{align*}
\end{lemma}
\begin{proof}
    考虑 $\sigma$ 在 $\mathbf{F}^n$ 的标准基底 $e_1, e_2, \ldots, e_n$ 上的值，设
    \[
        \sigma(e_1) = \begin{pmatrix} a_{11} \\ a_{21} \\ \vdots \\ a_{m1} \end{pmatrix},
        \sigma(e_2) = \begin{pmatrix} a_{12} \\ a_{22} \\ \vdots \\ a_{m2} \end{pmatrix},
        \ldots,
        \sigma(e_n) = \begin{pmatrix} a_{1n} \\ a_{2n} \\ \vdots \\ a_{mn} \end{pmatrix}
    \]
    由线性性，有
    \begin{align*}
        \sigma(x) &= \sigma(x_1 e_1 + x_2 e_2 + \cdots + x_n e_n) \\
        &= x_1 \sigma(e_1) + x_2 \sigma(e_2) + \cdots + x_n \sigma(e_n) \\
        &= \begin{pmatrix} a_{11} x_1 \\ a_{21} x_1 \\ \vdots \\ a_{m1} x_1 \end{pmatrix} +
        \begin{pmatrix} a_{12} x_2 \\ a_{22} x_2 \\ \vdots \\ a_{m2} x_2 \end{pmatrix} +
        \cdots +
        \begin{pmatrix} a_{1n} x_n \\ a_{2n} x_n \\ \vdots \\ a_{mn} x_n \end{pmatrix}\\
        &= \begin{pmatrix}
            a_{11} x_1 + a_{12} x_2 + \cdots + a_{1n} x_n \\
            a_{21} x_1 + a_{22} x_2 + \cdots + a_{2n} x_n \\
            \cdots\\
            a_{m1} x_1 + a_{m2} x_2 + \cdots + a_{mn} x_n
        \end{pmatrix}
    \end{align*}
\end{proof}

不难发现这里的 $a_{ij}$ 项实际上反映了输入的第 $j$ 项对输出的第 $i$ 项有多少权重，而只要确定了这 $m\times n$ 个权重，我们就得到了一个 $\mathbf{F}^n\to\mathbf{F}^m$ 的线性映射. 换言之，$\mathcal{L}(\mathbf{F}^n, \mathbf{F}^m)$ 和这些权重是一一对应的，于是一个映射可以等价地被记为一个矩阵，它接受一个 $\mathbf{F}^n$ 的向量，返回一个 $\mathbf{F}^m$ 的向量，由于标准基的存在，所以我们有同构 $\mathcal{L}(\mathbf{F}^n, \mathbf{F}^m) \cong \mathbf{F}^{m\times n}$ 后面不再区分 $\mathbf{F}^{m\times n}$ 和 $\mathcal{L}(\mathbf{F}^n, \mathbf{F}^m)$.
\[
    A = \begin{pmatrix}
        a_{11} & a_{12} & \cdots & a_{1n} \\
        a_{21} & a_{22} & \cdots & a_{2n} \\
        \vdots & \vdots & \ddots & \vdots \\
        a_{m1} & a_{m2} & \cdots & a_{mn}
    \end{pmatrix} \iff \forall x\in\mathbf{R}^n,
    A \begin{pmatrix}
        x_1 \\ x_2 \\ \vdots \\ x_n
    \end{pmatrix} = \begin{pmatrix}
        a_{11} x_1 + a_{12} x_2 + \cdots + a_{1n} x_n \\
        a_{21} x_1 + a_{22} x_2 + \cdots + a_{2n} x_n \\
        \cdots\\
        a_{m1} x_1 + a_{m2} x_2 + \cdots + a_{mn} x_n
    \end{pmatrix}
\]

我们可以这样计算矩阵作用在向量上的结果
\[
    \begin{pmatrix}
        1 & 2 & 3 \\ 4 & 5 & 6
    \end{pmatrix} \begin{pmatrix}
        7 \\ 8 \\ 9
    \end{pmatrix} = \begin{pmatrix}
        1\times 7 + 2\times 8 + 3\times 9 \\
        4 \times 7 + 5\times 8 + 6\times 9
    \end{pmatrix} = \begin{pmatrix}
        50 \\ 122
    \end{pmatrix}
\]

回顾第一章对线性方程的两种表示，一种是写成若干条方程，从行看去，每一行反映了输出的一项如何由输入线性组合得来. 另一种是像\autoref{线性方程的向量表示}中一样写成一条向量方程 $x_1\beta_1 + x_2\beta_2 + \cdots + x_n\beta_n = 0$，从列看去，每一列反映了输入的每一项会对输出产生怎么样的影响.

我们注意到虽然证明过程中我们假设了 $\sigma(e_j) = (a_{1j}, a_{2j}, \ldots, a_{mj})^{\mathrm{T}}$，但是即使把矩阵的列改成任意向量空间 $V$ 中的向量而非 $\mathbf{R}^m$ 中的向量也并不改变论证的有效性，也就是说矩阵的列完全可以被替换为任意向量空间中的元素，这样我们也就得到了 $\mathbf{R}^n \to V$ 的映射的一般表示方法——写成长度为 $n$ 的一行，每列分别是一个向量，例如当 $V = \mathbf{R}[x]_4$ 时，我们可以写出
\[
(1, x, x^2, x^3) \begin{pmatrix}
    1 \\ 2 \\ 3 \\ 4
\end{pmatrix} = 1 + 2x + 3x^2 + 4x^3
\]

我们可以将上面的运算称作使用 $\mathbf{F}^n$ 中向量的系数对一个向量组做线性组合. 特别地，由于基底也是一个向量组，当 $A$ 作为 $n$ 维向量空间 $V$ 的一个基底时，它作为 $\mathbf{F}^n\to V$ 的同构将坐标映射到空间中对应的点，和将点映射到坐标的坐标映射 $V\to\mathbf{F}^n$ 互为逆映射. 如果回顾\hyperlink{基底的矩阵写法}{基底的矩阵写法}我们便会发现前面的符号和此处达成了统一.

我们有一些常用的矩阵，例如零矩阵，即所有元素均为0的矩阵，通常记为$O$；单位矩阵也十分常见，它表示对角线上元素为1，其余元素为0的矩阵，通常记为$E$（若已知阶数为$n$也可特别记为$E_n$）其第 $j$ 列恰好为标准基底中的 $e_j$.

除此之外，我们通常记域$\mathbf{F}$上的$m\times n$矩阵全体为$\mathbf{F}^{m\times n}$或$\mathbf{M}_{m\times n}(\mathbf{F})$. 当$m=n$时矩阵称为方阵，域$\mathbf{F}$上全体$n$阶矩阵（或称$n$阶方阵）记为$\mathbf{F}^{n\times n}$或$\mathbf{M}_n(\mathbf{F})$.

在了解矩阵的定义之后，我们可以引入线性映射矩阵表示的概念. 经过前面大量的关于坐标同构的铺垫之后，想必读者对于如何将抽象的映射转化为矩阵有一个大致的思路，将一般的向量空间同构到我们熟悉的 $\mathbf{F}^n$，然后就可以得到矩阵表示. 但是在这之前笔者认为需要带读者了解交换图的基本工具

我们把空间抽象出来称为一个节点，空间之间的函数用箭头来表示，例如，如果有映射 $\psi\colon V_1 \to V_2, \sigma\colon V_2 \to V_3$，那么我们可以绘制交换图
\[
    \tikzcdset{arrow style=tikz, diagrams={>=stealth}}
    \begin{tikzcd}
        V_1 \arrow[r, "\psi"] & V_2 \arrow[r, "\sigma"] & V_3
    \end{tikzcd}
\]

交换图唯一的要求是从一个节点沿着箭头到另一个节点，函数的复合应当是相同的，例如在上面的图中，如果 $x\in V_1$ 经过两个映射，它会先变成 $\psi(x)$，然后得到 $\sigma(\psi(x)) = (\sigma\circ\psi)(x)$. 所以在上面的图中，如果要从 $V_1$ 引出一条箭头指向 $V_3$ 则这条箭头只能代表映射 $\sigma\circ\psi$（注意后经过的映射写在左侧，这与从左到右的书写习惯相反），类似地我们可以画出如下的图
\[
    \tikzcdset{arrow style=tikz, diagrams={>=stealth}}
    \begin{tikzcd}
        V_1 \arrow[r, "\psi"] \ar[rd, "\rho\circ\psi"'] & V_2 \arrow[d, "\rho"] \ar[rd, "\sigma\circ\rho"] \\ & V_3 \ar[r, "\sigma"'] & V_4
    \end{tikzcd}
\]

从图中我们可以读出 $\sigma\circ(\rho\circ\psi) = (\sigma\circ\rho)\circ\psi$，即映射复合的结合律. 自此，构造出指定的映射就可以图形化地表示成在图上画箭头，只要能够找到两个节点之间的一条通路，就能够通过映射的复合构造出一个映射.

接下来回到一般的线性映射. 我们知道一个 $\mathbf{F}$ 上的 $m\times n$ 矩阵可以作为一个 $\mathbf{F}^n\to\mathbf{R}^m$ 的映射，所以矩阵对应的应该是从 $\mathbf{F}^n$ 指向 $\mathbf{F}^m$ 的箭头. 一个向量组可以作为一个 $\mathbf{F}^n\to V$ 的映射，所以一个 $n$ 元向量组对应一条 $\mathbf{F}^n$ 指向 $V$ 的箭头. 对于基底这种特殊的向量组，其特性是可逆，于是在 $\mathbf{F}^n\to V$ 外可以另外添加一条反向的箭头表示坐标映射. 不妨设 $V_1$ 是 $\mathbf{F}$ 上的 $n$ 维向量空间，而 $V_2$ 是 $\mathbf{F}$ 上的 $m$ 维向量空间. 为了把映射 $\sigma\colon V_1\to V_2$ 用矩阵表示，我们需要先取两个基底：$B_1 = (\varepsilon_1, \varepsilon_2, \ldots, \varepsilon_n)\colon \mathbf{F}^n\to V_1$ 和 $B_2 = (\alpha_1, \alpha_2, \ldots, \alpha_m)\colon\mathbf{F}^m\to V_2$. 根据上面的两组基和一个映射画出交换图
\[
    \tikzcdset{arrow style=tikz, diagrams={>=stealth}}
    \begin{tikzcd}
        V_1 \arrow[r, "\sigma"]
        \arrow[d, gray, shift left, "B_1^{-1}"] &
        V_2 \arrow[d, gray, shift left, "B_2^{-1}"] \\
        \mathbf{F}^n \arrow[u, shift left, "B_1"] &
        \mathbf{F}^m \arrow[u, shift left, "B_2"]
    \end{tikzcd}
\]

这时构造出一个矩阵，即画出一条从 $\mathbf{F}^n\to\mathbf{F}^m$ 的箭头就十分自然了，只需要求出从 $\mathbf{F}^n$ 到 $\mathbf{F}^m$ 的映射复合就可以，沿着交换图的箭头不难读出我们所求的矩阵可以写成 $\mathbf{M}(\sigma) = B_2^{-1} \circ \sigma \circ B_1$. 又或者，如果考虑从 $\mathbf{F}^n$ 到 $V_2$ 的两条路径，也可以说它是唯一的矩阵使得 $\sigma \circ B_1 = B_2 \circ \mathbf{M}(\sigma)$
\[
    \tikzcdset{arrow style=tikz, diagrams={>=stealth}}
    \begin{tikzcd}
        V_1 \arrow[r, "\sigma"]
        \arrow[d, gray, shift left, "B_1^{-1}"] &
        V_2 \arrow[d, gray, shift left, "B_2^{-1}"] \\
        \mathbf{F}^n \arrow[u, shift left, "B_1"]
        \arrow[r, red, "\mathbf{M}(\sigma)"'] &
        \mathbf{F}^m \arrow[u, shift left, "B_2"]
    \end{tikzcd}
\]

事实上，如果从另一个角度思考，因为矩阵是多个$\mathbf{R}^m$中的向量并列在一起得到的方块，那么如何得到这些$\mathbf{R}^m$中的列向量呢？想必是某些向量在线性映射到达空间的一组基下的坐标. 于是我们很自然地可以接受下面的定义：
\begin{definition}{}{线性映射矩阵表示}
    设$B_1=\{\varepsilon_1,\varepsilon_2,\ldots,\varepsilon_n\}$是$V_1(\mathbf{F})$的基，$B_2=\{\alpha_1,\alpha_2,\ldots,\alpha_m\}$是$V_2(\mathbf{F})$的基. 则线性映射$\sigma \in \mathcal{L}(V_1,V_2)$被它作用于基$B_1$的像
    \[\sigma(B_1)=\{\sigma(\varepsilon_1),\sigma(\varepsilon_2),\ldots,\sigma(\varepsilon_n)\}\]
    所唯一确定，而$\sigma(B_1)$是$V_2$的子空间，于是其中元素都可以被基$B_2$线性表示，即
    \[ \begin{cases} \begin{aligned}
                \sigma(\varepsilon_1) & = a_{11}\alpha_1+a_{21}\alpha_2+\cdots+a_{m1}\alpha_m \\
                \sigma(\varepsilon_2) & = a_{12}\alpha_1+a_{22}\alpha_2+\cdots+a_{m2}\alpha_m \\
                                      & \vdotswithin{=}                                       \\
                \sigma(\varepsilon_n) & = a_{1n}\alpha_1+a_{2n}\alpha_2+\cdots+a_{mn}\alpha_m
            \end{aligned} \end{cases} \]
    将$\sigma(B_1)=\{\sigma(\varepsilon_1),\sigma(\varepsilon_2),\ldots,\sigma(\varepsilon_n)\}$关于基$B_2$的坐标排列成矩阵$\mathbf{M}(\sigma)$，即
    \[
        \mathbf{M}(\sigma)=\begin{pmatrix}
            a_{11} & a_{12} & \cdots & a_{1n} \\
            a_{21} & a_{22} & \cdots & a_{2n} \\
            \vdots & \vdots & \ddots & \vdots \\
            a_{m1} & a_{m2} & \cdots & a_{mn}
        \end{pmatrix}
    \]
    称$\mathbf{M}(\sigma)$为$\sigma$在基$B_1$和$B_2$下的矩阵表示，有时也称线性映射在基下的表示矩阵.
\end{definition}

如果分开来讨论映射 $\sigma \circ B_1 = B_2 \circ \mathbf{M}(\sigma) : \mathbf{F}^n\to V_2$ 中的每一列，线性映射矩阵 $\mathbf{M}(\sigma)$ 表示就是将线性映射 $\sigma$ 在一组基 $B_1$ 上的像在另一组基 $B_2$ 下的坐标表示按列排列得到的结果. 这一整体过程我们也可以用如下记号表示：
\begin{equation}\label{eq:7:线性映射矩阵表示}
    (\sigma(\varepsilon_1),\sigma(\varepsilon_2),\ldots,\sigma(\varepsilon_n))=(\alpha_1,\alpha_2,\ldots,\alpha_m)\mathbf{M}(\sigma).
\end{equation}

根据定义我们直接有如下简单的观察：
\begin{enumerate}
    \item 线性映射矩阵表示的结果是一个$m\times n$矩阵，其中$m$是到达空间的维数，$n$是出发空间的维数，特别注意此处有个次序的颠倒，务必区分清楚；

    \item 若$\sigma$在基下矩阵表示为$A=(a_{ij})_{m\times n}$，在出发空间的基的第$i$个向量在到达空间基下的坐标为$(a_{1i},a_{2i},\ldots,a_{mi})$，即矩阵$A$的第$i$列，或写为$\sigma(\varepsilon)=a_{1i}\alpha_1+a_{2i}\alpha_2+\cdots+a_{mi}\alpha_m$.
\end{enumerate}

想必有很多读者会心存疑惑：为什么我们要这么定义线性映射的矩阵表示呢？我们将在下一小节说明线性映射构成的线性空间与矩阵构成线性空间的同构时解释这一点. 现在先让我们完成以下几个例题熟悉定义：
\begin{example}{}{矩阵表示1}
    已知$\sigma \in \mathcal{L}(\mathbf{R}^3,\mathbf{R}^3)$且$\sigma(x_1,x_2,x_3)^{\color{lightgray}\mathrm{T}}=(x_1+x_2,x_1-x_3, x_2)^{\color{lightgray}\mathrm{T}}$
    \begin{enumerate}
        \item 求$\sigma$的像空间和核空间；

        \item 求$\sigma$关于$\mathbf{R}^3$自然基的矩阵.
    \end{enumerate}
\end{example}

\begin{solution}
    \begin{enumerate}
        \item 求像空间和核空间的方法我们在之前已经介绍过，我们为了计算方便取$\mathbf{R}^3$的自然基$e_1,e_2,e_3$计算有：
              \[
                \im\sigma
                =\spa(\sigma(e_1),\sigma(e_2),\sigma(e_3))
                =\spa(
                        (1,1,0)^{\color{lightgray}\mathrm{T}},
                        (1,0,1)^{\color{lightgray}\mathrm{T}},
                        (0,-1,0)^{\color{lightgray}\mathrm{T}}
                    )
                =\mathbf{R}^3
              \]
              对于核空间，解方程$\sigma(\alpha)=0$即可. 我们也可以用更简洁的方式书写：
              \[
                \ker\sigma
                =\{
                    (x_1,x_2,x_3)^{\color{lightgray}\mathrm{T}} \mid
                    \sigma(x_1,x_2,x_3)^{\color{lightgray}\mathrm{T}}
                    =(0,0,0)^{\color{lightgray}\mathrm{T}}
                \}
                =\{(0,0,0)^{\color{lightgray}\mathrm{T}}\}
              \]
              即方程只有零解，核空间可以记为$\ker\sigma=\{0\}$（只含零元的空间的一般记法）.

        \item 我们根据\autoref{def:线性映射矩阵表示}，应先写出$\sigma$在出发空间一组基（按题目要求是$\mathbf{R}^3$自然基）下的像，并将像表示为到达空间基（按题目要求是$\mathbf{R}^3$自然基）的线性组合，即
            \begin{gather*}
                \sigma(e_1) = (1,1,0)^{\color{lightgray}\mathrm{T}}
                =e_1+e_2=(e_1,e_2,e_3)\begin{pmatrix}
                    1 \\ 1 \\ 0
                \end{pmatrix} \\
                \sigma(e_2) = (1,0,1)^{\color{lightgray}\mathrm{T}}
                =e_1+e_3=(e_1,e_2,e_3)\begin{pmatrix}
                    1 \\ 0 \\ 1
                \end{pmatrix} \\
                \sigma(e_3) = (0,-1,0)^{\color{lightgray}\mathrm{T}}
                =-e_2=(e_1,e_2,e_3)\begin{pmatrix}
                    0 \\ -1 \\ 0
                \end{pmatrix}
            \end{gather*}
            接下来我们把坐标依次按列称矩阵就得到了本题需要求解的矩阵：
            \[
                \mathbf{M}(\sigma)=\begin{pmatrix}
                    1 & 1 & 0  \\
                    1 & 0 & -1 \\
                    0 & 1 & 0
                \end{pmatrix}
            \]
    \end{enumerate}
\end{solution}

有趣的是，在结合我个人的学习经历以及过往辅学的经验后，我总结出了第二问的一种常见的错误解法，这里我需要加粗强调，下面这种解法是\textbf{完全错误的！！！}这里展示这一解法是为了让读者将前面所学的知识完全厘清：

\begin{solution}[错误解法！！！]
    $
        \sigma(x_1,x_2,x_3)^{\color{lightgray}\mathrm{T}}
        =(x_1+x_2,x_1-x_3, x_2)=(x_1,x_2,x_3)\begin{pmatrix}
            1 & 1  & 0 \\
            1 & 0  & 1 \\
            0 & -1 & 0
        \end{pmatrix}
    $
\end{solution}

我们惊奇地发现，这一结果和我们前面得到的标准答案在向量的排列方式上发生了变化，即标准答案的1、2、3行变为了这里的1、2、3列，我们需要强调两点：
\begin{enumerate}
    \item 为什么这种解法是错误的：我们可以直接比较\autoref{eq:7:线性映射矩阵表示} 和这一解法中，\autoref*{eq:7:线性映射矩阵表示} 的等号左边是$n$个向量在$\sigma$下的像，而上述解法$\sigma(x_1,x_2,x_3)^{\color{lightgray}\mathrm{T}}$只是$\sigma$在一个向量下的像，这显然是不一样的！！！同样，等号右边括号内\autoref*{eq:7:线性映射矩阵表示} 是到达空间的一组基，而上述解法中仍然只是一个向量. 我们从未定义过这样解题的结果是什么，所以千万不能做这种无意义的事！！！

          容易导致混淆的原因可能在于我们书写$(x,y,z)$向量时是排列成一行的，可能看起来和$(e_1,e_2,e_3)$有点相似，但是如果我们回忆在第一章中的约定：写作行向量，实际是列向量，把 $\mathbf{R}^3$ 的向量按列书写之后我们得到的应该是
          \[
            \sigma\begin{pmatrix}
                x_1 \\ x_2 \\ x_3
            \end{pmatrix} = \begin{pmatrix}
                x_1 + x_2 \\ x_1 - x_3 \\ x_2
            \end{pmatrix} = \begin{pmatrix}
                1 & 1 & 0 \\ 1 & 0 & -1 \\  0 & 1 & 0
            \end{pmatrix} \begin{pmatrix}
                x_1 \\ x_2 \\ x_3
            \end{pmatrix} \implies
            \sigma = \begin{pmatrix}
                1 & 1 & 0 \\ 1 & 0 & -1 \\  0 & 1 & 0
            \end{pmatrix}
          \]
          当注意到这点之后，实际上我们也可以直接写出矩阵形式的 $\mathbf{R}^3 \to \mathbf{R}^3$ 的映射，由于标准基 $B_1 = B_2 = E$ 是单位阵，即恒同映射（坐标等于向量）所以 $\sigma\circ E = E\circ \mathbf{M}(\sigma)$ 退化为其标准表示 $\mathbf{M} = \sigma = \begin{pmatrix}
              1 & 1 & 0 \\ 1 & 0 & -1 \\  0 & 1 & 0
          \end{pmatrix}$.

    \item 为什么会出现行列互换这样的错误：
          事实上
          \[
            \sigma(x,y,z)^{\color{lightgray}\mathrm{T}}
            =\sigma(xe_1+ye_2+ze_3)
            =x\sigma(e_1)+y\sigma(e_2)+z\sigma(e_3)
            =(x,y,z)
            \begin{pmatrix}
                \sigma(e_1)^{\color{lightgray}\mathrm{T}} \\
                \sigma(e_2)^{\color{lightgray}\mathrm{T}} \\
                \sigma(e_3)^{\color{lightgray}\mathrm{T}}
            \end{pmatrix},
          \]
        这里将$\sigma(e_1),\sigma(e_2),\sigma(e_3)$的结果按行排列成矩阵，对比标准答案的 $(\sigma(e_1), \sigma(e_2), \sigma(e_3))$ 是将$\sigma(e_1),\sigma(e_2),\sigma(e_3)$在$\mathbf{R}^3$自然基下的坐标按列排列成矩阵，回忆$\mathbf{R}^n$向量在自然基下坐标是其本身这一性质，标准答案就是将$\sigma(e_1),\sigma(e_2),\sigma(e_3)$按列排列成矩阵，由此我们解释了行列互换发生的原因.
\end{enumerate}

这也就是为什么我强调读者不要参考之前提到的第二种方法\autoref{ex:线性映射的像空间求解2}来求解像空间——很容易导致这里矩阵表示犯这样的错误，并且容易导致初学时无法区分求解像空间和线性映射矩阵表示的方法. 在这里我必须再次强调：在没有完全熟练掌握这些概念和方法前，不要乱用方法！！！

接下来，我们还需要介绍旋转变换的矩阵表示
\begin{example}{}{}
    设$\sigma\colon\mathbf{R}^2\to\mathbf{R}^2$是绕原点逆时针旋转$\theta$角的变换，求$\sigma$在$\mathbf{R}^2$的自然基下的矩阵表示.
\end{example}
\begin{solution}
    求解的过程是很自然简单的，我们只需要考虑$\sigma$在常用基$e_1,e_2$下的像，即
    \[
    \begin{cases}
        \sigma(e_1)=\cos\theta e_1+\sin\theta e_2=(e_1,e_2)\begin{pmatrix}
            \cos\theta \\ \sin\theta
        \end{pmatrix} \\
        \sigma(e_2)=-\sin\theta e_1+\cos\theta e_2=(e_1,e_2)\begin{pmatrix}
            -\sin\theta \\ \cos\theta
        \end{pmatrix}
    \end{cases}
    \]
    故
    \[\mathbf{M}(\sigma)=\begin{pmatrix}
        \cos\theta & -\sin\theta \\
        \sin\theta & \cos\theta
    \end{pmatrix}\]

\end{solution}
这一矩阵形式可以记忆，在之后会多次出现.

\section{$\mathcal{L}(V_1,V_2)$与矩阵线性空间的同构}

本节我们将通过说明$\mathcal{L}(V_1,V_2)$与矩阵构成的线性空间的同构来解释为什么我们要这么定义线性映射的矩阵表示. 为了达到这一目标，我们首先需要证明这一同构.

\subsection{矩阵的加法和数乘}

回忆我们定义

本节我们将完善上一讲中同构的例子的细节，即若$\dim V_1(\mathbf{F})=m$，$\dim V_2(\mathbf{F})=n$，则 $\mathcal{L}(\mathbf{F}^n, \mathbf{F}^m)$ 中映射和其在 $\mathbf{F}^{m\times n}$ 中的标准表示一一对应. 于是 $\mathbf{F}^{m\times n}$ 便可以自然地从映射构成的线性空间 $\mathcal{L}(\mathbf{F}^n, \mathbf{F}^m)$ 中继承加法和数乘. 先考虑加法，由于 $(\sigma+\tau)(x) = \sigma(x) + \tau(x)$，令 $\sigma = (a_{ij})_{m\times n}, \tau = (b_{ij})_{m\times n}$ 则有
\begin{align*}
    &\phantom{=\ }((a_{ij})_{m\times n} + (b_{ij})_{m\times n})(x)\\
    &= (a_{ij})_{m\times n} (x) + (b_{ij})_{m\times n} (x) \\
    &= \begin{pmatrix}
        a_{11} x_1 + a_{12} x_2 + \cdots + a_{1n} x_n \\
        a_{21} x_1 + a_{22} x_2 + \cdots + a_{2n} x_n \\
        \cdots\\
        a_{m1} x_1 + a_{m2} x_2 + \cdots + a_{mn} x_n
    \end{pmatrix} + \begin{pmatrix}
        b_{11} x_1 + b_{12} x_2 + \cdots + b_{1n} x_n \\
        b_{21} x_1 + b_{22} x_2 + \cdots + b_{2n} x_n \\
        \cdots\\
        b_{m1} x_1 + b_{m2} x_2 + \cdots + b_{mn} x_n
    \end{pmatrix} \\
    &= \begin{pmatrix}
        (a_{11} + b_{11}) x_1 + (a_{12} + b_{12}) x_2 + \cdots + (a_{1n} + b_{1n}) x_n \\
        (a_{21} + b_{21}) x_1 + (a_{22} + b_{22}) x_2 + \cdots + (a_{2n} + b_{2n}) x_n \\
        \cdots\\
        (a_{m1} + b_{m1}) x_1 + (a_{m2} + b_{m2}) x_2 + \cdots + (a_{mn} + b_{mn}) x_n
    \end{pmatrix} \\
    &= \begin{pmatrix}
        a_{11} + b_{11} & a_{12} + b_{12} & \cdots & a_{1n} + b_{1n} \\
        a_{21} + b_{21} & a_{22} + b_{22} & \cdots & a_{2n} + b_{2n} \\
        \cdots\\
        a_{m1} + b_{m1} & a_{m2} + b_{m2} & \cdots & a_{mn} + b_{mn}
    \end{pmatrix}
    \begin{pmatrix}
        x_1 \\ x_2 \\ \vdots \\ x_n
    \end{pmatrix}
\end{align*}

即应该有
\[
    (a_{ij})_{m\times n} + (b_{ij})_{m\times n} = (a_{ij} + b_{ij})_{m\times n}
\]

类似地，由线性映射的数乘 $(\lambda \sigma)(x) = \lambda\cdot(\sigma(x)), \forall \lambda\in\mathbf{F}, x\in V$ 可以导出
\[
    \lambda (a_{ij})_{m\times n} = (\lambda a_{ij})_{m\times n} = \begin{pmatrix}
        \lambda a_{11} & \lambda a_{12} & \cdots & \lambda a_{1n} \\
        \lambda a_{21} & \lambda a_{22} & \cdots & \lambda a_{2n} \\
        \vdots & \vdots & \ddots & \vdots \\
        \lambda a_{m1} & \lambda a_{m2} & \cdots & \lambda a_{mn}
    \end{pmatrix}
\]

结合上面的推导，我们给出正式的矩阵加法和数乘定义
\begin{definition}{矩阵加法和数乘}{}
    (加法) 设 $A = (a_{ij})_{m\times n}, B = (b_{ij})_{m\times n} \in \mathbf{F}^{m\times n}$ 为矩阵，则定义
    \[
        A + B = \begin{pmatrix}
            a_{11} + b_{11} & a_{12} + b_{12} & \cdots & a_{1n} + b_{1n} \\
            a_{21} + b_{21} & a_{22} + b_{22} & \cdots & a_{2n} + b_{2n} \\
            \cdots\\
            a_{m1} + b_{m1} & a_{m2} + b_{m2} & \cdots & a_{mn} + b_{mn}
        \end{pmatrix}
    \]
    (数乘) 对 $\lambda\in\mathbf{F}$, 定义
    \[
        \lambda A = \begin{pmatrix}
            \lambda a_{11} & \lambda a_{12} & \cdots & \lambda a_{1n} \\
            \lambda a_{21} & \lambda a_{22} & \cdots & \lambda a_{2n} \\
            \vdots & \vdots & \ddots & \vdots \\
            \lambda a_{m1} & \lambda a_{m2} & \cdots & \lambda a_{mn}
        \end{pmatrix}
    \]
\end{definition}

前文已经证明了两个空间之间的全体线性映射构成线性空间，这里矩阵作为特殊的线性映射（$\mathbf{F}^n\to\mathbf{F}^m$），自然关于继承来的加法和乘法构成线性空间.

% deprecated
% 为此我们需要理解矩阵的加法和数乘是怎么样的.
% 我们有一个非常自然的想法——既然 $V_1\to V_2$ 的全体线性映射关于线性映射加法和数乘构成线性空间，那么我们也许可以利用线性映射加法与数乘运算的矩阵表示来定义加法和数乘运算.

% 我们首先回顾线性映射的加法和数乘运算：设$\sigma,\tau\in \mathcal{L}(V_1,V_2)$，规定$\sigma$与$\tau$之和及$\lambda$与$\sigma$的数乘$\lambda\sigma$分别为
% \begin{gather*}
%     (\sigma+\tau)(\alpha)=\sigma(\alpha)+\tau(\alpha),\enspace\forall\alpha\in V_1 \\
%     (\lambda\sigma)(\alpha)=\lambda(\sigma(\alpha)),\enspace\forall\alpha\in V_1
% \end{gather*}

% 回顾线性映射的矩阵表示，我们实际上是要计算出线性映射在出发空间一组基下的像在到达空间一组基下的坐标然后按列排列. 我们取$V_1$的基$B_1=\{\varepsilon_1,\varepsilon_2,\ldots,\varepsilon_n\}$，$V_2$的基$B_2=\{\alpha_1,\alpha_2,\ldots,\alpha_m\}$，假设$\sigma$和$\tau$在$B_1$和$B_2$下的矩阵分别为$A=(a_{ij})_{m\times n}$和$B=(b_{ij})_{m\times n}$，则
% \begin{gather*}
%     \sigma(\varepsilon_i)=a_{1i}\alpha_1+a_{2i}\alpha_2+\cdots+a_{mi}\alpha_m \\
%     \tau(\varepsilon_i)=b_{1i}\alpha_1+b_{2i}\alpha_2+\cdots+b_{mi}\alpha_m.
% \end{gather*}
% 因此
% \[(\sigma+\tau)(\varepsilon_i)=(a_{1i}+b_{1i})\alpha_1+(a_{2i}+b_{2i})\alpha_2+\cdots+(a_{mi}+b_{mi})\alpha_m,\enspace i=1,2,\ldots,n\]
% 即$(\sigma+\tau)$矩阵表示$\mathbf{M}(\sigma+\tau)$的第$i$列元素为$A$和$B$的第$i$列对应元素相加. 由于$i$是任取的，因此$(\sigma+\tau)$的矩阵表示每一列都是$A$和$B$同一列对应元素相加，实际上对于整个矩阵而言就是矩阵相同位置元素相加，即
% \begin{align*}
%     \mathbf{M}(\sigma+\tau) & =\begin{pmatrix}
%                                    a_{11}+b_{11} & a_{12}+b_{12} & \cdots & a_{1n}+b_{1n} \\
%                                    a_{21}+b_{21} & a_{22}+b_{22} & \cdots & a_{2n}+b_{2n} \\
%                                    \vdots        & \vdots        & \ddots & \vdots        \\
%                                    a_{m1}+b_{m1} & a_{m2}+b_{m2} & \cdots & a_{mn}+b_{mn}
%                                \end{pmatrix}     \\
%                             & \triangleq\begin{pmatrix}
%                                             a_{11} & a_{12} & \cdots & a_{1n} \\
%                                             a_{21} & a_{22} & \cdots & a_{2n} \\
%                                             \vdots & \vdots & \ddots & \vdots \\
%                                             a_{m1} & a_{m2} & \cdots & a_{mn}
%                                         \end{pmatrix} + \begin{pmatrix}
%                                                             b_{11} & b_{12} & \cdots & b_{1n} \\
%                                                             b_{21} & b_{22} & \cdots & b_{2n} \\
%                                                             \vdots & \vdots & \ddots & \vdots \\
%                                                             b_{m1} & b_{m2} & \cdots & b_{mn}
%                                                         \end{pmatrix} \\
%                             & =\mathbf{M}(\sigma)+\mathbf{M}(\tau).
% \end{align*}
% 式中$\triangleq$表示定义，即定义矩阵加法为矩阵对应元素相加. 同理，我们也可以通过线性映射的数乘定义矩阵数乘运算如下：
% \[\mathbf{M}(\lambda\sigma)=\begin{pmatrix}
%         \lambda a_{11} & \lambda a_{12} & \cdots & \lambda a_{1n} \\
%         \lambda a_{21} & \lambda a_{22} & \cdots & \lambda a_{2n} \\
%         \vdots         & \vdots         & \ddots & \vdots         \\
%         \lambda a_{m1} & \lambda a_{m2} & \cdots & \lambda a_{mn}
%     \end{pmatrix}\triangleq\lambda\begin{pmatrix}
%         a_{11} & a_{12} & \cdots & a_{1n} \\
%         a_{21} & a_{22} & \cdots & a_{2n} \\
%         \vdots & \vdots & \ddots & \vdots \\
%         a_{m1} & a_{m2} & \cdots & a_{mn}
%     \end{pmatrix}=\lambda\mathbf{M}(\sigma).\]

事实上从运算的形式看，这非常符合我们对于矩阵加法和数乘的幻想，即矩阵加法就是对应元素相加，矩阵数乘就是对应元素乘以一个数.

此外，在利用线性映射的加法和数乘定义了非常自然的矩阵加法和数乘后，我们也可以直接通过加法和数乘的定义证明 $m\times n$ 矩阵全体关于这两种运算构成线性空间. 这里我们只需回顾线性空间运算的八条要求然后逐一验证即可，实际上非常简单，因此不在此赘述.

\subsection{同构的说明}

在上一小节中我们借助映射定义了矩阵的加法和数乘运算，也说明了全体$m\times n$矩阵关于这两种运算构成线性空间$\mathbf{F}^{m\times n}$，接下来我们需要讨论的是对于$n$维线性空间$V_1$和$m$维线性空间$V_2$，$\mathcal{L}(V_1,V_2)$与$\mathbf{F}^{m\times n}$的同构. 即我们需要定义一个线性双射$\sigma:\mathcal{L}(V_1,V_2)\to\mathbf{F}^{m\times n}$. 事实上我们只需要取一组基，然后利用线性映射矩阵表示，即定义
\[
    \tikzcdset{arrow style=tikz, diagrams={>=stealth}}
    \begin{tikzcd}
        V_1 \arrow[r, "\sigma"]
        \arrow[d, gray, shift left, "B_1^{-1}"] &
        V_2 \arrow[d, gray, shift left, "B_2^{-1}"] &
        \mathcal{L}(V_1, V_2) \arrow[d, thick, red, "\cong"]\\
        \mathbf{F}^n \arrow[u, shift left, "B_1"]
        \arrow[r, "\mathbf{M}(\sigma)"'] &
        \mathbf{F}^m \arrow[u, shift left, "B_2"] &
        \mathcal{L}(\mathbf{F}^n, \mathbf{F}^m) = \mathbf{F}^{m\times n}
    \end{tikzcd}
    \varphi(\sigma)=\mathbf{M}_{\color{lightgray} B_1, B_2}(\sigma)\\
\]

也就是说$\varphi$将线性映射$\sigma$映射为其矩阵表示. 接下来需要验证$\varphi$是线性双射.
\begin{enumerate}
    \item 先证明线性性，因为根据矩阵加法和数乘的定义和基、坐标的线性性，我们有
          \begin{align*}
            \forall x\in\mathbf{F}^n, \\
            (\varphi(\sigma + \tau))(x)
            &= (B_2^{-1} \circ (\sigma + \tau) \circ B_1) (x) \\
            &= B_2^{-1} ((\sigma + \tau) (B_1 (x))) \\
            &= B_2^{-1} (\sigma (B_1 (x)) + \sigma (B_1 (x))) \\
            &= B_2^{-1} (\sigma (B_1 (x))) + B_2^{-1} (\sigma (B_1 (x))) \\
            &= (B_2^{-1} \circ \sigma \circ B_1) (x) + (B_2^{-1} \circ \tau \circ B_1) (x) \\
            &= (\varphi(\sigma))(x) + (\varphi(\tau))(x) \\
            &= (\varphi(\sigma) + \varphi(\tau))(x)\\
            &\implies \varphi(\sigma + \tau) = \varphi(\sigma) + \varphi(\tau)\\
            (\varphi(\lambda\sigma))(x)
            &= (B_2^{-1} \circ (\lambda\sigma) \circ B_1)(x)\\
            &= B_2^{-1} ((\lambda\sigma)(B_1(x)))\\
            &= B_2^{-1} (\lambda (\sigma(B_1(x))))\\
            &= \lambda (B_2^{-1} (\sigma (B_1(x))))\\
            &= (\lambda (B_2^{-1}\circ\sigma\circ B_1))(x)\\
            &= (\lambda \varphi(\sigma))(x)\\
            &\implies \varphi(\lambda\sigma) = \lambda \varphi(\sigma)
          \end{align*}
          % deprecated
          %   \begin{gather*}
          %     \varphi(\sigma+\tau)(x)=\mathbf{M}(\sigma+\tau)=\mathbf{M}(\sigma)+\mathbf{M}(\tau)=\varphi(\sigma)+\varphi(\tau) \\
          %     \varphi(\lambda\sigma)=\mathbf{M}(\lambda\sigma)=\lambda\mathbf{M}(\sigma)=\lambda\varphi(\sigma).
          %   \end{gather*}

    \item 双射也是显然的：
          基底是可逆映射，故 $\varphi(\sigma) = B_2^{-1} \circ \sigma \circ B_1$ 和 $\varphi^{-1}(M) =  B_2 \circ M \circ B_1^{-1}$ 互为逆映射，从而是双射.
        %   \begin{enumerate}
        %     \item 对于单射性，我们考察$\varphi$的核空间$\ker\varphi$中的元素$\sigma$，即$\sigma$在基下的矩阵表示为零矩阵，那么$\sigma$必然为零映射，因为它将所有基映射为0，故必然将所有出发空间元素映射为0，因此核空间为$\{0\}$，单射成立；

        %     \item 对于满射性，我们需要为任意$m\times n$矩阵$(a_{ij})_{m\times n}$找到一个线性映射，使得这一矩阵为这一线性映射在基下的矩阵表示. 事实上，给定基和矩阵表示，我们就知道了线性映射在出发空间的基下的像——因为给定到达空间的基和矩阵就给定了线性映射在出发空间的基在到达空间的基下的坐标. 然后根据\autoref{thm:线性映射构造} 知我们一定能找到这一映射，故满射性成立.
        %   \end{enumerate}
\end{enumerate}

这一同构不仅体现在线性空间的同构，更是体现在作为映射保持了映射对象的同步运算，换言之，$X \mapsto \mathbf{M}(\sigma)(x)$ 和 $\alpha \mapsto \sigma(\alpha)$ 是同步进行的. 即我们有重要定理:

\begin{theorem}{线性映射对向量坐标的影响}{线性映射对向量坐标的影响}
    设$\sigma \in \mathcal{L}(V_1,V_2)$关于$V_1$和$V_2$的基$B_1$和基$B_2$的矩阵为$A=(a_{ij})_{m \times n}$，且$\alpha$与$\sigma(\alpha)$在基$B_1=(\alpha_1,\ldots,\alpha_n)$和$B_2=(\beta_1,\ldots,\beta_m)$下的坐标分别为$X$和$Y$，则$Y=AX$.
\end{theorem}

\begin{proof}
    设$X=(x_1,\ldots,x_n)^\mathrm{T},\enspace Y=(y_1,\ldots,y_m)^\mathrm{T}$，由题意可知
    \begin{align*}
        \sigma(\alpha) & =\sigma(x_1\alpha_1+\cdots+x_n\alpha_n)                                 \\
                       & =x_1\sigma(\alpha_1)+\cdots+x_n\sigma(\alpha_n)                         \\
                       & =(\sigma(\alpha_1),\ldots,\sigma(\alpha_n))X \\
                       & =(\beta_1,\ldots,\beta_m)AX
    \end{align*}
    又由于$\sigma(\alpha)$在线性无关向量组$\beta_1,\ldots,\beta_m$下的坐标唯一，故我们有$Y=AX$.
\end{proof}

或者通过画图来说明这一点，由于一个 $n$ 维的列向量可以认为属于 $\mathbf{F}^{n\times 1}$，即看成是 $\mathbf{F} \to \mathbf{F}^n$ 的矩阵（其乘以 $\mathbf{F}$ 中的标量 $k$ 等同于用 $k$ 数乘），假设向量 $\alpha, \sigma(\alpha)$ 在两个基底下分别有坐标 $X,Y$. 起手先画出我们熟悉的矩阵表示的图，然后向其上按照关系 $\alpha = B_1 X, \sigma(\alpha) = B_2 Y$ 添加箭头 $\alpha, X, Y$. 接下来就可以从图中直接读出 $Y=AX$
\[
    \tikzcdset{arrow style=tikz, diagrams={>=stealth}}
    \begin{tikzcd}
        V_1
            \arrow[r, "\sigma"]
            \arrow[d, gray, shift left, "B_1^{-1}"]
        & V_2
            \arrow[d, gray, shift left, "B_2^{-1}"]
        \\ \mathbf{F}^n
            \arrow[u, shift left, "B_1"]
            \arrow[r, "A"']
        & \mathbf{F}^m
            \arrow[u, shift left, "B_2"]
        \\ \color{red}\mathbf{F}
            \arrow[uu, red, bend left=60, "\alpha"]
            \arrow[u, red, "X"]
            \arrow[ur, red, "Y"']
    \end{tikzcd}
\]

解释如下：我们可以取任意的线性映射$\sigma:V_1\to V_2$，在$V_1$和$V_2$的基$B_1$和$B_2$下的矩阵表示为$A$. 这里有$V_1$和$V_2$中的向量在基下的坐标分别是$\mathbf{F}^n$和$\mathbf{F}^m$中的向量. 根据\autoref{thm:线性映射对向量坐标的影响}，$\tau(\alpha)=\beta$中$\beta$和$\alpha$坐标之间的关联为$Y=AX$，这就相当于在$\mathbf{F}^n$和$\mathbf{F}^m$中的向量之间建立了一个与$A:V_1\to V_2$同步的映射$X\mapsto AX$，每当$V$中向量经过$\sigma$映射后，它的坐标也就经过了$A$的映射.

由此我们证明了$\mathcal{L}(V_1,V_2)\cong\mathbf{F}^{m\times n}$是一种线性映射层面的同构. 而我们很容易知道，$\mathbf{F}^{m\times n}$的维数为$mn$. 事实上对于矩阵关于矩阵加法和数乘构成的线性空间，我们有如下一组常用基：$E_{ij}(i=1,\ldots,m,j=1,\ldots,n)$，其中每个$E_{ij}$为第$i$行$j$列元素为1，其余元素全为0的矩阵. 例如对于$\mathbf{F}^{2\times 3}$，根据前面的描述我们可以写出其常用基为：
\[E_{11}=\begin{pmatrix}
        1 & 0 & 0 \\
        0 & 0 & 0
    \end{pmatrix},\enspace E_{12}=\begin{pmatrix}
        0 & 1 & 0 \\
        0 & 0 & 0
    \end{pmatrix},\enspace E_{13}=\begin{pmatrix}
        0 & 0 & 1 \\
        0 & 0 & 0
    \end{pmatrix},\]
\[E_{21}=\begin{pmatrix}
        0 & 0 & 0 \\
        1 & 0 & 0
    \end{pmatrix},\enspace E_{22}=\begin{pmatrix}
        0 & 0 & 0 \\
        0 & 1 & 0
    \end{pmatrix},\enspace E_{23}=\begin{pmatrix}
        0 & 0 & 0 \\
        0 & 0 & 1
    \end{pmatrix},\]
事实上，我们很容易验证这样的常用基的确是线性空间$\mathbf{F}^{m\times n}$的一组基，因为它们显然是线性无关的，且张成整个空间（请读者自行验证），然后我们也知道这样的常用基中矩阵有$m\times n$个，由此我们也得到了$\dim\mathcal{L}(V_1,V_2)=mn$. 当然我们还可以有另一种理解方式，如果读者已经学习过编程中二维数组的概念，事实上二维数组在计算机中的存储形式是一行存完接着马上存下一行，因此事实上我们可以将二维数组看作是一个长为$m\times n$的一维数组（方法就是第一行写完后在同一行马上接着写第二行元素，写完后在同一行接着写第三行元素，依此类推），因此我们也可以理解为$\mathbf{F}^{m\times n}$和$\mathbf{F}^{mn}$是没有区别的（容易验证是同构的），因此$\dim\mathbf{F}^{m\times n}=mn$.

\section{线性映射与矩阵的进一步讨论}

\begin{summary}

    在上一讲同构中我们已经知道，两个（有限维）线性空间中的元素是向量还是多项式还是函数并不是核心差别，只要它们维数相同，我们就可以遮蔽掉元素的差别——因为它们都可以通过坐标映射同构于 $\mathbf{F}^n$，因此一切线性空间在坐标作用下都变成了向量空间，变成了最直观的可以用一个一个数字写出来的向量，而本讲我们正基于此将所有无论多么抽象的线性映射也表示成能用一个一个数字写出来的东西，即所谓的矩阵. 我们利用坐标映射将之前抽象的线性空间和线性映射转化为具象的数字表达，使得我们之后的研究更加具体.

    在理解了线性映射矩阵表示的概念之后，我们给出了一个重要的例子，同时从反面给出了错误解法，希望读者务必厘清这其中涉及的各种概念和方法. 接下来我们证明了线性映射构成的线性空间与矩阵构成的线性空间同构，同时引入了矩阵的加法和数乘——这与线性映射的加法和数乘是完全对应的. 总而言之，在有了线性映射的矩阵表示后，我们便可以将抽象的研究都转化为具象的矩阵运算，这一思想我们将在介绍完需要的工具——矩阵运算以及行列式之后深入运用，届时我们将分别以抽象的线性映射理论和矩阵理论叙述大量的结论，探寻利用二者研究线性代数问题的过程的关联与差异.

\end{summary}

\begin{exercise}
    \exquote[S. 乌拉姆（Stanisław Ulam）]{一个定理有什么用并不重要，真正重要的是它有多优雅。}

    % \begin{exgroup}
    %
    % \end{exgroup}

    \begin{exgroup}[2] % 如果取消注释上面的 exgroup，删除此处 [2]
        \item 设$B=\{\beta_1,\beta_2,\ldots,\beta_n\}$是实数域$\mathbf{R}$上的线性空间$V$的一组基，$T \in L(V),\enspace T(\beta_1)=\beta_2,T(\beta_2)=\beta_3,\ldots,T(\beta_{n-1})=T(\beta_n),T(\beta_n)=\displaystyle\sum_{i=1}^{n}a_i\beta_i(a_i \in \mathbf{R})$，求$T$关于基$B$的表示矩阵，并求在什么条件下$T$是同构映射.
        \begin{answer}
            $ T(\beta_1, \beta_2, \ldots, \beta_n) = (\beta_1, \beta_2, \ldots, \beta_n)A $，其中
            \[ A = \begin{pmatrix}
                      &   &        &   & a_1    \\
                    1 &   &        &   & a_2    \\
                      & 1 &        &   & a_3    \\
                      &   & \ddots &   & \vdots \\
                      &   &        & 1 & a_n
                \end{pmatrix} \]
            是 $ T $ 关于基 $ B $ 的表示矩阵.
  
            $ T $ 是同构 $ \iff T $ 是双射 $ \iff r(T) = n $，满秩. 所以当 $ a_1 \neq 0 $ 时，$ r(T) = n $ 满秩，此时 $ T $ 是同构映射.
        \end{answer}

        \item 已知$f_1=1-x,f_2=1+x^2,f_3=x+2x^2$是$\mathbf{R}[x]_3$中三个元素，$\sigma$是$\mathbf{R}[x]_3$上的线性变换且满足$\sigma(f_1)=2+x^2,\sigma(f_2)=x,\sigma(f_3)=1+x+x^2$.
        \begin{enumerate}
            \item 证明：$f_1,f_2,f_3$构成$\mathbf{R}[x]_3$的一组基；

            \item 求$\sigma$在基$f_1,f_2,f_3$下的矩阵；

            \item 设$f=1+2x+3x^2$，求$\sigma(f)$.
        \end{enumerate}
        
        \begin{answer}
            \begin{enumerate}
                \item 只需要证明$f_1,f_2,f_3$是线性无关的即可，事实上，这也十分显然(考虑其在$1,x,x^2$下的坐标表示线性无关),想必读者可以自行证明
  
                \item 方法一：设 $ (\sigma(f_1), \sigma(f_2), \sigma(f_3)) = (f_1, f_2, f_3) A $，则由
                      \[ (\sigma(f_1), \sigma(f_2), \sigma(f_3)) = (1, x, x^2) \begin{pmatrix}
                              2 & 0 & 1 \\
                              0 & 1 & 1 \\
                              2 & 0 & 1
                          \end{pmatrix} = (1, x, x^2) \begin{pmatrix}
                              1  & 1 & 0 \\
                              -1 & 0 & 1 \\
                              0  & 1 & 2
                          \end{pmatrix} A \]
                      可得
                      \begin{align*}
                          A & = \begin{pmatrix}
                                    1  & 1 & 0 \\
                                    -1 & 0 & 1 \\
                                    0  & 1 & 2
                                \end{pmatrix}^{-1}
                          \begin{pmatrix}
                              2 & 0 & 1 \\
                              0 & 1 & 1 \\
                              1 & 0 & 1
                          \end{pmatrix}           \\
                            & = \begin{pmatrix}
                                    -1 & -2 & 1  \\
                                    2  & 2  & -1 \\
                                    -1 & -1 & 1
                                \end{pmatrix}
                          \begin{pmatrix}
                              2 & 0 & 1 \\
                              0 & 1 & 1 \\
                              1 & 0 & 1
                          \end{pmatrix}
                          = \begin{pmatrix}
                                -1 & -2 & -2 \\
                                3  & 2  & 3  \\
                                -1 & -1 & -1
                            \end{pmatrix}
                      \end{align*}
  
                      方法二：通过待定系数法解方程组
                      \[ \begin{cases}
                              \sigma(f_1) = -f_1 + 3 f_2 - f_3   \\
                              \sigma(f_2) = -2 f_1 + 2 f_2 - f_3 \\
                              \sigma(f_3) = -2 f_1 + 3 f_2 - f_3
                          \end{cases} \]
                      解得
                      \[ (\sigma(f_1), \sigma(f_2), \sigma(f_3)) = (f_1, f_2, f_3) \begin{pmatrix}
                              -1 & -2 & -2 \\
                              3  & 2  & 3  \\
                              -1 & -1 & -1
                          \end{pmatrix} \]
  
                \item \begin{align*}
                          \sigma(f) & = \sigma\left((1, x, x^2)
                          \begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix}\right)= \sigma\left((f_1, f_2, f_3)
                          \begin{pmatrix}
                              1  & 1 & 0 \\
                              -1 & 0 & 1 \\
                              0  & 1 & 2
                          \end{pmatrix}^{-1} \begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix}\right) \\
                                    & = (\sigma(f_1), \sigma(f_2), \sigma(f_3))
                          \begin{pmatrix}
                              1  & 1 & 0 \\
                              -1 & 0 & 1 \\
                              0  & 1 & 2
                          \end{pmatrix}^{-1} \begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix}        \\
                                    & = (1, x, x^2)
                          \begin{pmatrix}
                              2 & 0 & 1 \\
                              0 & 1 & 1 \\
                              1 & 0 & 1
                          \end{pmatrix}
                          \begin{pmatrix}
                              1  & 1 & 0 \\
                              -1 & 0 & 1 \\
                              0  & 1 & 2
                          \end{pmatrix}^{-1}
                          \begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix}                           \\
                                    & = (1, x, x^2)
                          \begin{pmatrix} -4 \\ 3 \\ 2 \end{pmatrix}                          \\
                                    & = 2x^2 + 3x - 4
                      \end{align*}
  
                      或也可采用待定系数法求出 $ f = -2 f_1 + 3 f_2 $，所以 $ \sigma(f) = -2 \sigma(f_1) + 3 \sigma(f_2) = 2x^2 + 3x - 4 $.
            \end{enumerate}
        \end{answer}

        \item 设$V=\mathbf{M}_2(\mathbf{R})$是$\mathbf{R}$上所有$2 \times 2$矩阵构成的实数域上的线性空间. 已知
        \[A=\begin{pmatrix}1 & -1 \\ \lambda & 1 \end{pmatrix}(\lambda \in \mathbf{R}),\enspace B=\begin{pmatrix}1 & 2 \\ -1 & -1 \end{pmatrix}\]
        \begin{enumerate}
            \item 证明：$\varphi(X)=AXB$为$V$上的线性变换；

            \item 证明：$\lambda\neq-1$时，$\varphi$为可逆线性变换；

            \item \label{item:7:B:1}
                  $\lambda=-1$时，求$\varphi$的像空间和核空间；

            \item 将 \ref*{item:7:B:1} 中的值域扩充为$V$的一组基，并求$\varphi$在这组基下的矩阵.
        \end{enumerate}

        \begin{answer}
            \begin{enumerate}
                \item $ \forall X, Y \in \mathbf{M}_2(\mathbf{R}),\enspace k_1, k_2 \in \mathbf{R} $，有
                      \begin{align*}
                          \varphi(k_1 X + k_2 Y) & = A(k_1 X + k_2 Y)B               \\
                                                 & = k_1 A X B + k_2 A Y B           \\
                                                 & = k_1 \varphi(X) + k_2 \varphi(Y)
                      \end{align*}
                      所以 $ \varphi $ 是 $ \mathbf{M}_2(\mathbf{R}) $ 上的线性映射.
  
                \item 证明：易知 $ B $ 可逆. 当 $ \lambda = -1 $ 时，$ A $ 可逆. 故 $ \varphi $ 可逆，$ \varphi^{-1}(X) = A^{-1} X B^{-1} $.
  
                \item $ \lambda = -1 $ 时，取 $ V $ 的一组基 $ \alpha_1 = \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}, \alpha_2 = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}, \alpha_3 = \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix}, \alpha_4 = \begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix} $，有
                      \begin{gather*}
                          \begin{aligned}
                              \im \sigma & = \spa(\varphi(\alpha_1), \varphi(\alpha_2), \varphi(\alpha_3), \varphi(\alpha_4))                                \\
                                         & = \spa\left(\begin{pmatrix} 1 & 2 \\ -1 & -2 \end{pmatrix}, \begin{pmatrix} -1 & -1 \\ 1 & 1 \end{pmatrix}\right)
                          \end{aligned} \\
                          \ker \sigma = \spa\left(\begin{pmatrix} 2 & -3 \\ 0 & 1 \end{pmatrix}, \begin{pmatrix} 1 & 0 \\ 1 & 0 \end{pmatrix}\right)
                      \end{gather*}
                      （步骤略，答案不唯一）
  
                \item 取 $ \begin{pmatrix} 1 & 2 \\ -1 & -2 \end{pmatrix}, \begin{pmatrix} -1 & -1 \\ 1 & 1 \end{pmatrix}, \alpha_3, \alpha_4 $ 即可. 此时矩阵为$ \begin{pmatrix}
                              2 & -2 & -1 & 0 \\
                              4 & -2 & 0  & 1 \\
                              0 & 1  & 0  & 0 \\
                              0 & 0  & 0  & 0
                          \end{pmatrix} $. （答案不唯一）
            \end{enumerate}  
        \end{answer}

        \item 设矩阵空间$\mathbf{R}^{2\times 2}$的子空间为
        \[V=\{X=(x_{ij})_{2\times 2} \mid x_{11}+x_{12}+x_{21}=0,\enspace x_{ij}\in \mathbf{R}\}\]
        V中的线性变换为$\sigma(X)=X+X^\mathrm{T}$，求$V$的一组基，使得$\sigma$在该基下的矩阵表示为对角矩阵.

        \begin{answer}
            我们可以类比线性空间
          \[ W = \{ x \in \mathbf{R}^4 \mid x_1 + x_2 + x_3 = 0 \} \]
          $ W $ 的基只需求解线性方程组 $ x_1 + x_2 + x_3 = 0 $ 即可，得到基础解系为 $ (-1, 0, 1, 0)^{\mathrm{T}},\allowbreak (-1, 1, 0, 0)^{\mathrm{T}},\allowbreak (0, 0, 0, 1)^{\mathrm{T}} $.

          换回 $ V $，即有基为 $ A_1 = \begin{pmatrix} -1 & 0 \\ 1 & 0 \end{pmatrix}, A_2 = \begin{pmatrix} -1 & 1 \\ 0 & 0 \end{pmatrix}, A_3 = \begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix} $. 而
          \begin{align*}
                         & \sigma(A_1) = \begin{pmatrix} -2 & 1 \\ 1 & 0 \end{pmatrix} = A_1 + A_2                      \\
                         & \sigma(A_2) = \begin{pmatrix} -2 & 1 \\ 1 & 0 \end{pmatrix} = A_1 + A_2                      \\
                         & \sigma(A_3) = \begin{pmatrix} -2 & 1 \\ 1 & 0 \end{pmatrix} = 2 A_3                          \\
              \implies{} & \sigma(A_1 + A_2) = 2(A_1 + A_2),\enspace \sigma(A_1 - A_2) = 0,\enspace \sigma(A_3) = 2 A_3
          \end{align*}
          取基 $ A_1 - A_2, A_1 + A_2, A_3 $，有
          \[ (\sigma(A_1 - A_2), \sigma(A_1 + A_2), \sigma(A_3)) = (A_1 - A_2, A_1 + A_2, A_3) = \begin{pmatrix}
                  0 & 0 & 0 \\
                  0 & 2 & 0 \\
                  0 & 0 & 2
              \end{pmatrix} \]
          为对角矩阵.
        \end{answer}

        \item 设 $\mathbf{R}[x]_4$ 是数域 $\mathbf{R}$ 上次数小于 4 的多项式所构成的线性空间（约定零多项式次数为 $-\infty$）. $\mathbf{M}_2(\mathbf{R})$ 是 $\mathbf{R}$ 上 2 阶方阵所构成的线性空间. 定义 $T \colon \mathbf{R}[x]_4 \to \mathbf{M}_2(\mathbf{R})$ 如下：对 $f(x) \in \mathbf{R}[x]_4$，
        \[T(f(x))=\begin{pmatrix}f(0) & f(1) \\ f(-1) & f(0)\end{pmatrix}\]
        \begin{enumerate}
            \item 求出 $T$ 的核空间 $N(T)$ 和像空间 $R(T)$；

            \item 求$T$在$\mathbf{R}[x]_4$和$\mathbf{M}_2(\mathbf{R})$的基下的矩阵表示.
        \end{enumerate}

        \begin{answer}
            \begin{enumerate}
                \item \label{item:7:B:5:1}
                      求核空间，即求使得 $ T(f(x)) $ 为零矩阵的 $ f(x) $ 构成的空间. 设 $ f(x) = ax^3 + bx^2 + cx + d $，则有
                      \[ \begin{cases}
                              f(0) = d = 0             \\
                              f(1) = a + b + c + d = 0 \\
                              f(-1) = -a + b -c + d = 0
                          \end{cases} \]
                      解方程，令 $ a = t $ 有
                      \[ \begin{cases}
                              a = t  \\
                              b = 0  \\
                              c = -t \\
                              d = 0
                          \end{cases} \implies f(x) = t(x^3 - x) \]
                      故 $ N(T) = \spa(x^3 - x) $.
  
                      求像空间，取 $ \mathbf{R}[x]_4 $ 的自然基 $ 1, x, x^2, x^3 $.
                      \[ \begin{matrix}
                              T(1) = \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}   & T(x) = \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix}   \\
                              T(x^2) = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} & T(x^3) = \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix}
                          \end{matrix} \]
                      求它们的极大线性无关组. 我们发现 $ T(x) = T(x^3) $，故先舍弃 $ T(x^3) $，然后令
                      \begin{align*}
                                     & k_1 T(1) + k_2 T(x) + k_3 T(x^2) = 0                                             \\
                          \implies{} & \begin{pmatrix} k_1 & k_1 + k_2 + k_3 \\ k_1 - k_2 + k_3 & k_1 \end{pmatrix} = 0 \\
                          \implies{} & \begin{cases}
                                           k_1 = 0             \\
                                           k_1 + k_2 + k_3 = 0 \\
                                           k_1 - k_2 + k_3 = 0 \\
                                       \end{cases}                                                              \\
                          \implies{} & k_1 = k_2 = k_3 = 0
                      \end{align*}
                      故 $ T(1), T(x), T(x^2) $ 线性无关. 故 $ R(T) = \spa\left(\begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}, \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix}, \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}\right) $.
  
                \item 我们只需要将$2 \times 2$矩阵的第二列拼到第一列下方就可以变为我们熟悉的列向量形式，所以其矩阵表示也是简单的
                      \[
                        T(1,x,x^2,x^3)=(e_1,e_2,e_3,e_4)\begin{pmatrix}
                            1 & 0 & 0 & 0 \\
                            1 & -1 & 1 & -1 \\
                            1 & 1 & 1 & 1 \\
                            1 & 0 & 0 & 0
                        \end{pmatrix}
                      \]

                      其中$e_1=\begin{pmatrix}1&0\\0&0\end{pmatrix}$,$e_2=\begin{pmatrix}0&0\\1&0\end{pmatrix}$,
                      $e_3=\begin{pmatrix}0&1\\0&0\end{pmatrix}$,$e_4=\begin{pmatrix}0&0\\0&1\end{pmatrix}$.
            \end{enumerate}
        \end{answer}

        \item 设$A=\begin{pmatrix}
                1 & -1 & -1 \\ -1 & 1 & 1 \\ 0 & -4 & 2
            \end{pmatrix},\enspace\xi_1=(-1,1,-2)^\mathrm{T}$.
        \begin{enumerate}
            \item 求满足$A\xi_2=\xi_1$及$A^2\xi_3=\xi_1$的所有$\xi_2,\xi_3$；

            \item 证明：$\xi_1,\xi_2,\xi_3$线性无关.
        \end{enumerate}
        
        \begin{answer}
            \begin{enumerate}
                \item 对非齐次线性方程组$AX=\xi_1$，\\
                      $\bar{A}=\begin{pmatrix}
                              1  & -1 & -1 & -1 \\
                              -1 & 1  & 1  & 1  \\
                              0  & -4 & -2 & -2
                          \end{pmatrix}
                          \rightarrow\begin{pmatrix}
                              1 & -1 & -1       & -1       \\
                              0 & 1  & \frac 12 & \frac 12 \\
                              0 & 0  & 0        & 0
                          \end{pmatrix}
                          \rightarrow\begin{pmatrix}
                              1 & 0 & -\frac 12 & -\frac 12 \\
                              0 & 1 & \frac 12  & \frac 12  \\
                              0 & 0 & 0         & 0
                          \end{pmatrix}$，则\\
                      $\xi_2=C_1\begin{pmatrix}
                              \frac 12  \\
                              -\frac 12 \\
                              1
                          \end{pmatrix} + \begin{pmatrix}
                              -\frac 12 \\
                              \frac 12  \\
                              0
                          \end{pmatrix}=\dfrac 12\begin{pmatrix}
                              C_1 - 1  \\
                              -C_1 + 1 \\
                              2C_1
                          \end{pmatrix}$（其中$C_1$为任意常数）.\\
                      $A^2=\begin{pmatrix}
                              2  & 2  & 0 \\
                              -2 & -2 & 0 \\
                              4  & 4  & 0
                          \end{pmatrix}$，对齐次线性方程组$A^2X=\xi_1$，\\
                      $\bar{B}=\begin{pmatrix}
                              A^2 & \xi_1
                          \end{pmatrix}=\begin{pmatrix}
                              2  & 2  & 0 & 1  \\
                              -2 & -2 & 0 & 1  \\
                              4  & 4  & 0 & -2
                          \end{pmatrix}
                          \rightarrow\begin{pmatrix}
                              1 & 1 & 0 & -\frac 12 \\
                              0 & 0 & 0 & 0         \\
                              0 & 0 & 0 & 0
                          \end{pmatrix}$，\\
                      则$A^2X=\xi_1$的通解\\
                      $\xi_3=C_2\begin{pmatrix}
                              -1 \\
                              1  \\
                              0
                          \end{pmatrix}+C_3\begin{pmatrix}
                              0 \\
                              0 \\
                              1
                          \end{pmatrix}+\begin{pmatrix}
                              -\frac 12 \\
                              0         \\
                              0
                          \end{pmatrix}=\begin{pmatrix}
                              -C_2 - \frac 12 \\
                              C_2             \\
                              C_3
                          \end{pmatrix}$（其中$C_2, C_3$为任意常数）.
                \item
                      因为$|\xi_1,\xi_2,\xi_3|=\dfrac 12\begin{vmatrix}
                              -1 & C_1 - 1  & -C_2 - \frac 12 \\
                              1  & -C_1 + 1 & C_2             \\
                              -2 & 2C_1     & C_3
                          \end{vmatrix}=-\dfrac 12\neq 0$，\\
                      所以$\xi_1,\xi_2,\xi_3$线性无关.
            \end{enumerate}
        \end{answer}

        \item 已知$V$为有限维线性空间，$\sigma\in \mathcal{L}(V,V)$，且$\ker\sigma=\im \sigma$，证明：
        \begin{enumerate}
            \item $n$为偶数；

            \item 存在$V$的一组基$\alpha_1,\ldots,\alpha_n$使得
                  \[\sigma(\alpha_1,\ldots,\alpha_n)=(\alpha_1,\ldots,\alpha_n)\begin{pmatrix}
                          0 & E_{\frac{n}{2}} \\ 0 & 0
                      \end{pmatrix}.\]
        \end{enumerate}

        \begin{answer}
            证明：\begin{enumerate}
                \item 由于 $ \ker \sigma = \im \sigma $，由 $ \dim \im \sigma + \dim \ker \sigma = \dim V $ 可得.
  
                \item 设 $ \beta_1, \ldots, \beta_n $ 为 $ V $ 的一组基，则
                      \[ \im \sigma = \spa(\sigma(\beta_1), \ldots, \sigma(\beta_n)) = \ker \sigma \]
                      设 $ \sigma(\beta_1), \ldots, \sigma(\beta_{\frac{n}{2}}) $ 为 $ \im \sigma $ 的基，则可以证明
                      \[ \sigma(\beta_1), \ldots, \sigma(\beta_{\frac{n}{2}}), \beta_1, \ldots, \beta_{\frac{n}{2}} \]
                      线性无关，且 $ \sigma $ 在此基下的矩阵即为所求的形式.
            \end{enumerate}
  
        \end{answer}
    \end{exgroup}

    % \begin{exgroup}
    %
    % \end{exgroup}

\end{exercise}
